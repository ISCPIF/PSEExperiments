
@import org.openmole.site.Objects._


@sect{Batch systems}
  Many distributed computing environments offer @a("batch processing", href := "https://en.wikipedia.org/wiki/Batch_processing") capabilities. OpenMOLE supports most of the batch systems. Batch systems generally work by exposing an entry point on which the user can log on and submit jobs. OpenMOLE accesses this entry point using SSH.

  @p The first thing to do to be able to use you batch system with OpenMOLE is to provide your authentication information to OpenMOLE.

  @part.SSHAuthentication()

  @sect{PBS / Torque}
    @a("PBS", href :="http://en.wikipedia.org/wiki/Portable_Batch_System") is a venerable batch system for clusters. You may use a PBS computing environment as follow:
    @br @hl.openmole("""
    val env =
      PBSEnvironment(
        "login",
        "machine.domain"
      )""")

   @p @provideOptions:
   @ul
     @li{@port,}
     @li{@workDirectory,}
     @li{@queue,}
     @li{@wallTime,}
     @li{@memory,}
     @li{@openMOLEMemory,}
     @li{nodes: Number of nodes requested,}
     @li{@threads,}
     @li{coreByNodes: An alternative to specifying the number of threads. If it's not specified, it takes the value of threads, or 1 if none of them was specified.}
  @sect{SGE}
    To delegate some computation load to a @a("SGE", href := "https://en.wikipedia.org/wiki/Oracle_Grid_Engine") based cluster you can use the SGEEnvironment as follow:
    @br @hl.openmole("""
    val env =
      SGEEnvironment(
        "login",
        "machine.domain"
      )""")
    @p @provideOptions:
    @ul
      @li{@port,}
      @li{@workDirectory,}
      @li{@queue,}
      @li{@wallTime,}
      @li{@memory,}
      @li{@openMOLEMemory,}
      @li{@threads.}
  @sect{SLURM}
    To delegate some computation load to a @a("SLURM", href := "https://en.wikipedia.org/wiki/Simple_Linux_Utility_for_Resource_Management") based cluster you can use the SLURM environment as follow:
    @br @hl.openmole("""
    val env =
      SLURMEnvironment(
        "login",
        "machine.domain",
        // optional parameters
        gres = List( Gres("resource", 1) ),
        constraints = List("constraint1", "constraint2")
      )""")
    @p @provideOptions:
    @ul
      @li{@port,}
      @li{@workDirectory,}
      @li{@queue,}
      @li{@wallTime,}
      @li{@memory,}
      @li{@openMOLEMemory,}
      @li{nodes: Number of nodes requested,}
      @li{@threads,}
      @li{coresByNodes: An alternative to specifying the number of threads. If it's not specified, it takes the value of threads, or 1 if none of them was specified.}
      @li{qos: Quality of Service (QOS) as defined in the Slurm database}
      @li{gres: a list of Generic Resource (GRES) requested. A Gres is a pair defined by the name of the resource and the number of resources requested (scalar).}
      @li{constraints: a list of Slurm defined constraints which selected nodes must match.}
  @sect{Condor}
    To delegate some computation load to a @a("Condor", href := "https://en.wikipedia.org/wiki/HTCondor") condor based cluster you can use the CondorEnvironment as follow:
    @br @hl.openmole("""
    val env =
      CondorEnvironment(
        "login",
        "machine.domain"
      )""")
    @p @provideOptions:
    @ul
      @li{@port,}
      @li{@workDirectory,}
      @li{@memory,}
      @li{@openMOLEMemory,}
      @li{@threads.}
  @sect{OAR}
    To delegate some computation load to an @a("OAR", href := "http://oar.imag.fr/dokuwiki/doku.php") cluster, you can do a follow:
    @br @hl.openmole("""
    val env =
      OAREnvironment(
        "login",
        "machine.domain"
      )""")
    @p @provideOptions:
    @ul
      @li{@port,}
      @li{@workDirectory,}
      @li{@queue,}
      @li{@wallTime,}
      @li{@openMOLEMemory,}
      @li{@threads,}
      @li{core: number of core allocated for each job,}
      @li{cpu: number of CPUs allocated for each job.}
