
@import org.openmole.site.Objects._

@sect{Strainer capsule}
  In a general manner you are expected to specify the inputs and outputs of each task. The strainer mode of capsules transmits adds all the variable arriving through the input transition as if they were inputs of the task and also adds them as if they were outputs.
  @p For instance in the following workflow the variable @i{i} is transmitted to the hook without adding it explicitly in input and output of the task @i{t2}:
  @br @hl.openmole("""
  val i = Val[Int]
  val j = Val[Int]

  val t1 = ScalaTask("val i = 42") set (outputs += i)

  val t2 = ScalaTask("val j = i * 2") set (outputs += j)
  val c2 = Capsule(t2, strainer = true)

  val ex = t1 -- (c2 hook ToStringHook(i, j)) start
  """)

  @p This workflow displays @hl.highlight("{i=42, j=84}", "plain")

@sect{Master slave workflows}
  OpenMOLE provide a very flexible workflow formalism. It even makes it possible to design workflows with a part that mimic a master / slave distribution scheme for which many slaves jobs run and a master gather the result. You can think of steady state genetic algorithm of instance, for which a global solution population is maintained and a bunch of slave workers compute fitnesses in a distributed manner. Each time a worker ends, its result is used to update the global population and a new worker is launched. To achieve such a distribution scheme that one should use the master capsule and end exploration transition.

  @p The master capsule is a special capsule that preserve a state from one execution to another. An execution of the master capsule modify this state and the next execution get the state that as been lastly modify. To ensure soundness of the state only, the master capsules are always executed locally and multiple executions of a given master capsule are carried sequentially.

  @p By using the master capsule a workflow can evolve a global archive and compute new input to be evaluated from this archive. Even if it is not required, a master capsule is generally executed in an exploration, in order to have several workers computing concurrently. In these distribution scheme all the workers should be killed when the global archive has reached a suitable state. This this the aim of the end exploration transition, which is noted >|.

  @p The following script orchestrate a master slave distribution scheme for a dummy problem. 10 workers are launched and the selection task, placed in the master capsule, stores the numbers that are multiple of 3 and relaunch a worker for the next value of i. The second argument of the master capsule constructor is the data that should be persisted from one execution of the master capsule to another.
  @br @hl.openmole("""
  val i = Val[Int]
  val archive = Val[Array[Int]]

  val exploration = ExplorationTask(i in (0 until 10 toDomain))

  val model = ScalaTask("i = i + 7") set (inputs += i, outputs += i)

  val modelCapsule = Capsule(model)
  val modelSlot1 = Slot(modelCapsule)
  val modelSlot2 = Slot(modelCapsule)

  val select =
    ScalaTask("archive = archive ++ (if(i % 3 == 0) Seq(i) else Seq())") set (
      inputs += (i, archive),
      outputs += (i, archive),
      archive := Array[Int]()
    )

  val selectCaps = MasterCapsule(select, archive)

  val finalTask = EmptyTask()

  val displayHook = ToStringHook()

  val skel = exploration -< modelSlot1 -- (selectCaps hook displayHook)
  val loop = selectCaps -- modelSlot2
  val terminate = selectCaps >| (Capsule(finalTask, strainer = true) hook displayHook, "archive.size() >= 10")

  val ex = skel + loop + terminate
  ex.start""")